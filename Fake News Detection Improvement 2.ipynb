{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg0sadTeeMO2",
        "outputId": "3d5b6680-30f8-4991-a8df-e03f3e417f06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv                               # csv reader\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import sys\n",
        "import string\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtCFLaXfeXjD",
        "outputId": "1ba06d2a-410c-4f5a-eacf-047ed4c84615"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
        "    data=pd.DataFrame()\n",
        "    \n",
        "    with open(\"fake_news.tsv\") as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        for line in reader:\n",
        "            if line[0] == \"Id\":  # skip header\n",
        "              continue\n",
        "            (label, text,dic) = parse_data_line(line) \n",
        "            #currenlty returing the label, the statement and dictionary value of columns:total_half_true_counts, total_mostly_true_counts as key and value as 1 \n",
        "            raw_data.append((text, label,dic))  # appending the text, label and the new dictionary in raw data \n",
        "\n",
        "def split_and_preprocess_data(percentage):\n",
        "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
        "    and performs the preprocessing.\"\"\"\n",
        "    num_samples = len(raw_data)\n",
        "    num_training_samples = int((percentage * num_samples))\n",
        "    \n",
        "    for (text, label,dic) in raw_data[:num_training_samples]:\n",
        "        train_data.append((to_feature_vector(pre_process(text,\"False\"),dic),label)) # to_feature_vector takes two arguments, the tokens which it converts to dictionary and the dictionary from raw_data\n",
        "    for (text, label,dic) in raw_data[num_training_samples:]:\n",
        "        test_data.append((to_feature_vector(pre_process(text,\"False\"),dic),label))\n",
        "        "
      ],
      "metadata": {
        "id": "1dds3Gp8eZow"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_label(label):\n",
        "    \"\"\"Converts the multiple classes into two,\n",
        "    making it a binary distinction between fake news and real.\"\"\"\n",
        "    #return label\n",
        "    # Converting the multiclass labels to binary label\n",
        "    labels_map = {\n",
        "        'true': 'REAL',\n",
        "        'mostly-true': 'REAL',\n",
        "        'half-true': 'REAL',\n",
        "        'false': 'FAKE',\n",
        "        'barely-true': 'FAKE',\n",
        "        'pants-fire': 'FAKE'\n",
        "    }\n",
        "    return labels_map[label]\n",
        "\n",
        "\n",
        "def parse_data_line(data_line):\n",
        "    \n",
        "    label=convert_label(data_line[1]) #label element: data_line[1] read from file\n",
        "    text=data_line[2] #statement element: data_line[2] read from file\n",
        "    \n",
        "    dic3=dict.fromkeys(data_line[8:14],1) #creating dictionary for all the columns with column value as key and value as 1\n",
        "    dic2=dict.fromkeys(data_line[8:9]+data_line[9:10]+data_line[12:13],1) #creating dictionary for total_barely_true_counts, total_false_counts,total_pants_on_fire_counts with column value as key and value as 1\n",
        "    dic1=dict.fromkeys(data_line[10:11] + data_line[11:12],1) #creating dictionary for total_half_true_counts, total_mostly_true_counts with column value as key and value as 1\n",
        "    \n",
        "    return (label, text,dic1)"
      ],
      "metadata": {
        "id": "Z5GIZH9peckY"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect=[]\n",
        "def pre_process(text,stopword=\"False\"):\n",
        "    \n",
        "    text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text) # separates punctuation at ends of strings\n",
        "    text = re.sub(r\"([.,;:!?'\\\"“\\(\\)])(\\w)\", r\"\\1 \\2\", text) # separates punctuation at beginning of strings\n",
        "    tokens = re.split(r\"\\s+\",text)\n",
        "    tokens = [t.lower() for t in tokens]\n",
        "    wnl = WordNetLemmatizer()\n",
        "    for i in range(0,len(tokens)):\n",
        "      tokens[i]=wnl.lemmatize(tokens[i])\n",
        "    if stopword==\"True\": # Use only to check that the accuracy drops by removing stop words\n",
        "      N = stopwords.words('english')\n",
        "      word_stop=[]\n",
        "      for i in tokens:\n",
        "        if i not in N:\n",
        "          word_stop.append(i)\n",
        "      x1=[]\n",
        "      for i in range(2,len(word_stop)):\n",
        "        x1.append(('{0}{1}'.format(word_stop[i-2],''.join(word_stop[i-1])))) #Creating Bigram\n",
        "    \n",
        "      return x1\n",
        "    else:\n",
        "      x=[]\n",
        "      for i in range(2,len(tokens)):\n",
        "        x.append(('{0}{1}'.format(tokens[i-2],''.join(tokens[i-1])))) #Creating Bigram\n",
        "        \"\"\" Not using the * here as 5th question because it was used only for glue, unglue check, \n",
        "        as unglue was not useful hence discarding it.\"\"\"\n",
        "\n",
        "    \n",
        "    return x\n"
      ],
      "metadata": {
        "id": "5YR57KvFegE1"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_feature_dict = {} # A global dictionary of features\n",
        "\n",
        "def to_feature_vector(tokens,dic):\n",
        "    \n",
        "    local_dict={}\n",
        "    for i in tokens:\n",
        "      if i in local_dict:\n",
        "        #if i not in k:\n",
        "          if i in (\"percent\",\"state\",\"years\",\"states\",\"year\",\"people\",\"million\",\"would\",\"jobs\",\"one\",\"us\",\"new\",\"since\",\"texas\",\"every\"):\n",
        "            local_dict[i]+=5\n",
        "          else:\n",
        "            local_dict[i]+=1\n",
        "      else:\n",
        "        #if i not in k:\n",
        "          local_dict[i]=1\n",
        "    \n",
        "    for w in tokens:\n",
        "          try:\n",
        "            i = global_feature_dict[w]\n",
        "          \n",
        "          except KeyError:\n",
        "            i = len(global_feature_dict) + 1\n",
        "                \n",
        "            global_feature_dict[w] = i\n",
        "    local_dict.update(dic)\n",
        "    return local_dict       "
      ],
      "metadata": {
        "id": "MSQUUoD5e1my"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "\n",
        "def train_classifier(data,lin,mul,log,ran):\n",
        "    print(\"Training Classifier...\")\n",
        "    \n",
        "    if lin==\"True\":\n",
        "      pipeline = Pipeline([('model', LinearSVC(class_weight={0:1,1:1.2},C=0.006))])\n",
        "    elif mul==\"True\":\n",
        "      pipeline = Pipeline([('model', MultinomialNB())])\n",
        "    elif log==\"True\":\n",
        "      pipeline = Pipeline([('model', LogisticRegression())])\n",
        "    elif ran==\"True\":\n",
        "      pipeline = Pipeline([('model', RandomForestClassifier())])\n",
        "    \n",
        "    \n",
        "    return SklearnClassifier(pipeline).train(data)"
      ],
      "metadata": {
        "id": "PX6sKRW9e2Dr"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import NONE\n",
        "#solution\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "def cross_validate(dataset, folds):\n",
        "    results = []\n",
        "    fold_size = int(len(dataset)/folds) + 1\n",
        "    cv=np.array([])\n",
        "    accuracy=[]\n",
        "    precision=[]\n",
        "    recall=[]\n",
        "    f1=[]\n",
        "    j=0\n",
        "\n",
        "    for i in range(0,len(dataset),int(fold_size)):\n",
        "        data_fold=dataset[0:i]+dataset[i+fold_size:]\n",
        "        test_fold=dataset[i:i+fold_size]\n",
        "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
        "        print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
        "        # FILL IN THE METHOD HERE\n",
        "        classifier=train_classifier(data_fold,\"True\",\"False\",\"False\",\"False\")\n",
        "        predict=predict_labels([x[0] for x in test_fold],classifier)\n",
        "        if i ==7380:\n",
        "          global_test.append([x[1] for x in test_fold])\n",
        "          global_predict.append(predict)\n",
        "          global_test_text.append([x[0] for x in test_fold])\n",
        "        accuracy.append(accuracy_score([x[1] for x in test_fold],predict))\n",
        "        precision.append(precision_score([x[1] for x in test_fold], predict, average='weighted'))\n",
        "        recall.append(recall_score([x[1] for x in test_fold], predict, average='weighted'))\n",
        "        f1.append(f1_score([x[1] for x in test_fold], predict, average='weighted'))\n",
        "\n",
        "        \n",
        "    cv=[np.mean(accuracy),np.mean(precision),np.mean(recall),np.mean(f1)]\n",
        "           \n",
        "    return cv"
      ],
      "metadata": {
        "id": "dpoJdwhZe5S6"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predict_labels(samples, classifier):\n",
        "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
        "    return classifier.classify_many(samples)\n",
        "\n",
        "def predict_label_from_raw(sample, classifier):\n",
        "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
        "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
      ],
      "metadata": {
        "id": "BSuYPD5Re7Ot"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "raw_data = []          # the filtered data from the dataset file\n",
        "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
        "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
        "global_test=[]\n",
        "global_predict=[]\n",
        "global_test_text=[]\n",
        "global_text=[]\n",
        "d=[]\n",
        "data=pd.DataFrame()\n",
        "\n",
        "# references to the data files\n",
        "data_file_path = 'fake_news.tsv'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "\n",
        "load_data(data_file_path) \n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "\n",
        "split_and_preprocess_data(0.8)\n",
        "\n",
        "\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blrML1n8e914",
        "outputId": "e55aee0d-e77e-4810-dca2-d905f0ac018b"
      },
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 10240 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "After split, 10240 rawData, 8192 trainData, 2048 testData\n",
            "Training Samples: \n",
            "8192\n",
            "Features: \n",
            "82706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validate(train_data, 10)  # will work and output overall performance of p, r, f-score when cv implemented"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rRKVfGaheFN",
        "outputId": "017ad74f-8932-4dfa-ef10-6c8bede78d92"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold start on items 0 - 820\n",
            "Training Classifier...\n",
            "Fold start on items 820 - 1640\n",
            "Training Classifier...\n",
            "Fold start on items 1640 - 2460\n",
            "Training Classifier...\n",
            "Fold start on items 2460 - 3280\n",
            "Training Classifier...\n",
            "Fold start on items 3280 - 4100\n",
            "Training Classifier...\n",
            "Fold start on items 4100 - 4920\n",
            "Training Classifier...\n",
            "Fold start on items 4920 - 5740\n",
            "Training Classifier...\n",
            "Fold start on items 5740 - 6560\n",
            "Training Classifier...\n",
            "Fold start on items 6560 - 7380\n",
            "Training Classifier...\n",
            "Fold start on items 7380 - 8200\n",
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6593289679202211, 0.6632643753484906, 0.6593289679202211, 0.641366899951796]"
            ]
          },
          "metadata": {},
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "# a function to make the confusion matrix readable and pretty\n",
        "def confusion_matrix_heatmap(y_test, preds, labels):\n",
        "    \"\"\"Function to plot a confusion matrix\"\"\"\n",
        "    # pass labels to the confusion matrix function to ensure right order\n",
        "    cm = metrics.confusion_matrix(y_test, preds,labels=labels)\n",
        "    print(cm)\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm)\n",
        "    plt.title('Confusion matrix of the classifier')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticks(np.arange(len(labels)))\n",
        "    ax.set_yticks(np.arange(len(labels)))\n",
        "    ax.set_xticklabels( labels, rotation=45)\n",
        "    ax.set_yticklabels( labels)\n",
        "\n",
        "    for i in range(len(cm)):\n",
        "        for j in range(len(cm)):\n",
        "            text = ax.text(j, i, cm[i, j],\n",
        "                           ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    # fix for mpl bug that cuts off top/bottom of seaborn viz:\n",
        "    b, t = plt.ylim() # discover the values for bottom and top\n",
        "    b += 0.5 # Add 0.5 to the bottom\n",
        "    t -= 0.5 # Subtract 0.5 from the top\n",
        "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
        "    plt.show() # ta-da!\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "f69ImQbghi-e"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_heatmap(global_test[0],global_predict[0],[\"REAL\",\"FAKE\"]) #Plotting confusion matrix on the last fold of data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "b31LduEZUw8E",
        "outputId": "35971fd6-b7fd-46a9-82d0-10dd402ef5e2"
      },
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[408  71]\n",
            " [183 150]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "functions_complete = True  # set to True once you're happy with your methods for cross val\n",
        "if functions_complete:\n",
        "    print(test_data[0])   # have a look at the first test data instance\n",
        "    classifier = train_classifier(train_data,\"True\",\"False\",\"False\",\"False\")  # train the classifier, sending Boolean for other models as well\n",
        "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
        "    test_pred = predict_labels([x[0] for x in test_data], classifier)  # classify the test data to get predicted labels\n",
        "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
        "    accuracy=accuracy_score(test_true, test_pred)\n",
        "    print(\"Done training!\")\n",
        "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])\n",
        "    print(\"Accuracy\",accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTKNZozlwUEj",
        "outputId": "25ab79d3-e06b-455a-812a-0cf737a691f7"
      },
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "({'wehave': 1, 'haveinvested': 1, 'investedrecord': 1, 'recordfunding': 1, 'fundingin': 1, 'inprotecting': 1, 'protectingour': 1, 'ourenvironment': 1, '38': 1, '34': 1}, 'FAKE')\n",
            "Training Classifier...\n",
            "Done training!\n",
            "Precision: 0.664650\n",
            "Recall: 0.654297\n",
            "F Score:0.635609\n",
            "Accuracy 0.654296875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6uPH3p_sB4N9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}