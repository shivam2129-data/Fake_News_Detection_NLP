{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg0sadTeeMO2",
        "outputId": "369f9d83-b2a3-455f-94ee-c290f381a9c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv                               # csv reader\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import sys\n",
        "import string\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtCFLaXfeXjD",
        "outputId": "ef48f19d-25a7-463d-a457-4f2e09ceee95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(path):\n",
        "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
        "    \n",
        "    \n",
        "    with open(\"fake_news.tsv\") as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        for line in reader:\n",
        "            if line[0] == \"Id\":  # skip header\n",
        "                continue   \n",
        "            d.append(line)\n",
        "            (label, text) = parse_data_line(line)\n",
        "            raw_data.append((text, label))       \n",
        "\n",
        "def split_and_preprocess_data(percentage):\n",
        "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
        "    and performs the preprocessing.\"\"\"\n",
        "    num_samples = len(raw_data)\n",
        "    num_training_samples = int((percentage * num_samples))\n",
        "    \n",
        "    for (text, label) in raw_data[:num_training_samples]:\n",
        "        train_data.append((to_feature_vector(pre_process(text,\"False\")),label)) # pre_process now takes 2 arguments, set true when want to do stop word removal \n",
        "    for (text, label) in raw_data[num_training_samples:]:\n",
        "        test_data.append((to_feature_vector(pre_process(text,\"False\")),label))\n",
        "        "
      ],
      "metadata": {
        "id": "1dds3Gp8eZow"
      },
      "execution_count": 244,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_label(label):\n",
        "    \"\"\"Converts the multiple classes into two,\n",
        "    making it a binary distinction between fake news and real.\"\"\"\n",
        "    #return label\n",
        "    # Converting the multiclass labels to binary label\n",
        "    labels_map = {\n",
        "        'true': 'REAL',\n",
        "        'mostly-true': 'REAL',\n",
        "        'half-true': 'REAL',\n",
        "        'false': 'FAKE',\n",
        "        'barely-true': 'FAKE',\n",
        "        'pants-fire': 'FAKE'\n",
        "    }\n",
        "    return labels_map[label]\n",
        "\n",
        "\n",
        "def parse_data_line(data_line):\n",
        "    \n",
        "    label=convert_label(data_line[1]) #label element: data_line[1] read from file\n",
        "    text=data_line[2] #statement element: data_line[2] read from file\n",
        "    return (label, text)"
      ],
      "metadata": {
        "id": "Z5GIZH9peckY"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process(text,stopword=\"False\"):\n",
        "    # Sentence segmentation is already done as the sentences are provided as different rows\n",
        "    # word tokenisation\n",
        "    text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text) # separates punctuation at ends of strings by replacing the punctations by the string\n",
        "    text = re.sub(r\"([.,;:!?'\\\"“\\(\\)])(\\w)\", r\"\\1 \\2\", text) # separates punctuation at beginning of strings by replacing the punctations by the string\n",
        "    tokens = re.split(r\"\\s+\",text) # with space as delimeter it split the spaced text\n",
        "    tokens = [t.lower() for t in tokens]\n",
        "    wnl = WordNetLemmatizer() \n",
        "    for i in range(0,len(tokens)):\n",
        "      tokens[i]=wnl.lemmatize(tokens[i]) # Lemmatizing strings to thier dictionry forms\n",
        "    if stopword==\"True\": # Use only to check that the accuracy drops by removing stop words\n",
        "      N = stopwords.words('english')\n",
        "      word_stop=[]\n",
        "      for i in tokens:\n",
        "        if i not in N:\n",
        "          word_stop.append(i)\n",
        "      x1=[]\n",
        "      for i in range(2,len(word_stop)):\n",
        "        x1.append(('{0}*{1}'.format(word_stop[i-2],''.join(word_stop[i-1])))) #Creating Bigram\n",
        "    \n",
        "      return x1\n",
        "    else:\n",
        "      x=[]\n",
        "      for i in range(2,len(tokens)):\n",
        "        x.append(('{0}*{1}'.format(tokens[i-2],''.join(tokens[i-1])))) #Creating Bigram\n",
        "    \n",
        "    return x\n"
      ],
      "metadata": {
        "id": "5YR57KvFegE1"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_feature_dict = {} # A global dictionary of features\n",
        "\n",
        "def to_feature_vector(tokens):\n",
        "    \n",
        "    local_dict={}\n",
        "    x1=[]\n",
        "    st=[\"percent\",\"state\",\"years\",\"states\",\"year\",\"people\",\"million\",\"would\",\"jobs\",\"one\",\"us\",\"new\",\"since\",\"texas\",\"every\"]\n",
        "    for i in range(2,len(st)):\n",
        "      x1.append(('{0}*{1}'.format(st[i-2],''.join(st[i-1])))) #gluing the frequent Real words in the same format as Bigram of tokens for comaprison\n",
        "    \n",
        "\n",
        "    unglue=\"False\"\n",
        "\n",
        "    if unglue==\"False\": # Accuracy reduces if we unglue the tokens and then check, hence seeting to false\n",
        "      for i in tokens:\n",
        "        if i in local_dict:\n",
        "            if i in x1:\n",
        "              local_dict[i]+=5 # Adding 5 to the value of key if key already present in dictionary and also present in frequent words\n",
        "            else:\n",
        "              local_dict[i]+=1 # Adding 1 to the value of key if key already present in dictionary and not present in frequent words\n",
        "        else:\n",
        "          \n",
        "            local_dict[i]=1 # Adding key-value(value as 1) pair to the dictionary\n",
        "    if unglue==\"True\":  # Set to true only if you wish to verify that accuracy reduces from 60.2% to 59.1%\n",
        "      st=[\"percent\",\"state\",\"years\",\"states\",\"year\",\"people\",\"million\",\"would\",\"jobs\",\"one\",\"us\",\"new\",\"since\",\"texas\",\"every\"]\n",
        "      local_dict={}\n",
        "      for i in tokens:\n",
        "        if i in local_dict:\n",
        "            z=i\n",
        "            x=z.split(\"*\")\n",
        "            if x[0] in st or x[1] in st:\n",
        "              local_dict[i]+=5  #Adding 5 to the value of key if key already present in dictionary and not present in frequent words\n",
        "            else:\n",
        "              local_dict[i]+=1  #Adding 1 to the value of key if key already present in dictionary and not present in frequent words\n",
        "        else:\n",
        "            z=i\n",
        "            x=z.split(\"*\")\n",
        "            if x[0] in st or x[1] in st:\n",
        "              local_dict[i]=5 #Adding key-value(value as 5) pair to the dictionary if present in frequent word\n",
        "            else:\n",
        "              local_dict[i]=1   # Adding key-value(value as 1) pair to the dictionary if not preset in frequent word\n",
        "            \n",
        "    for w in tokens:\n",
        "          try:\n",
        "            i = global_feature_dict[w] # Checks if the key is already present in the dictionary, do nothing\n",
        "          \n",
        "          except KeyError:\n",
        "            i = len(global_feature_dict) + 1 # If it is not present then we add 1 to the length of the dictioanry\n",
        "                \n",
        "            global_feature_dict[w] = i # Then assign the new length as the value to the new key\n",
        "            \n",
        "    return local_dict       "
      ],
      "metadata": {
        "id": "MSQUUoD5e1my"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "\n",
        "def train_classifier(data,lin,mul,log,ran): # using boolean values to select differet models just to check accuracy for reference.\n",
        "    print(\"Training Classifier...\")\n",
        "    \n",
        "    if lin==\"True\":\n",
        "      pipeline = Pipeline([('model', LinearSVC(class_weight={0:1.1,1:1},C=0.006))]) #Decreasing cost parameter to penalizing samples inside the marging less\n",
        "                                                                                    #And giving more weight to Real\n",
        "    elif mul==\"True\":\n",
        "      pipeline = Pipeline([('model', MultinomialNB())])\n",
        "    elif log==\"True\":\n",
        "      pipeline = Pipeline([('model', LogisticRegression())])\n",
        "    elif ran==\"True\":\n",
        "      pipeline = Pipeline([('model', RandomForestClassifier())])\n",
        "    \n",
        "    \n",
        "    return SklearnClassifier(pipeline).train(data)"
      ],
      "metadata": {
        "id": "PX6sKRW9e2Dr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validate(dataset, folds):\n",
        "    results = []\n",
        "    fold_size = int(len(dataset)/folds) + 1\n",
        "    cv=np.array([])\n",
        "    accuracy=[]\n",
        "    precision=[]\n",
        "    recall=[]\n",
        "    f1=[]\n",
        "    j=0\n",
        "\n",
        "    for i in range(0,len(dataset),int(fold_size)):\n",
        "        data_fold=dataset[0:i]+dataset[i+fold_size:]\n",
        "        test_fold=dataset[i:i+fold_size]\n",
        "        # insert code here that trains and tests on the 10 folds of data in the dataset\n",
        "        print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
        "        # FILL IN THE METHOD HERE\n",
        "        classifier=train_classifier(data_fold,\"True\",\"False\",\"Flase\",\"False\")\n",
        "        predict=predict_labels([x[0] for x in test_fold],classifier)\n",
        "        if i ==7380:\n",
        "          global_test.append([x[1] for x in test_fold])\n",
        "          global_predict.append(predict)\n",
        "          global_test_text.append([x[0] for x in test_fold])\n",
        "        accuracy.append(accuracy_score([x[1] for x in test_fold],predict))\n",
        "        precision.append(precision_score([x[1] for x in test_fold], predict, average='weighted'))\n",
        "        recall.append(recall_score([x[1] for x in test_fold], predict, average='weighted'))\n",
        "        f1.append(f1_score([x[1] for x in test_fold], predict, average='weighted'))\n",
        "\n",
        "        \n",
        "    cv=[100*np.mean(accuracy),100*np.mean(precision),100*np.mean(recall),100*np.mean(f1)]\n",
        "           \n",
        "    return cv"
      ],
      "metadata": {
        "id": "dpoJdwhZe5S6"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predict_labels(samples, classifier):\n",
        "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
        "    return classifier.classify_many(samples)\n",
        "\n",
        "def predict_label_from_raw(sample, classifier):\n",
        "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
        "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
      ],
      "metadata": {
        "id": "BSuYPD5Re7Ot"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "raw_data = []          # the filtered data from the dataset file\n",
        "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
        "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
        "global_test=[]\n",
        "global_predict=[]\n",
        "global_test_text=[]\n",
        "global_text=[]\n",
        "d=[]\n",
        "\n",
        "\n",
        "# references to the data files\n",
        "data_file_path = 'fake_news.tsv'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "\n",
        "load_data(data_file_path) \n",
        "\n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "\n",
        "split_and_preprocess_data(0.8)\n",
        "\n",
        "\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "blrML1n8e914",
        "outputId": "35cc9944-5672-4d51-b726-7a90361c6803"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-60f08289fbd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \"Preparing the dataset...\",sep='\\n')\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# We split the raw dataset into a set of training data and a set of test data (80/20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validate(train_data, 10)  # will work and output overall performance of p, r, f-score when cv implemented"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rRKVfGaheFN",
        "outputId": "c6880919-a9dd-4e04-ab50-3a3bc2bd91b6"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold start on items 0 - 820\n",
            "Training Classifier...\n",
            "Fold start on items 820 - 1640\n",
            "Training Classifier...\n",
            "Fold start on items 1640 - 2460\n",
            "Training Classifier...\n",
            "Fold start on items 2460 - 3280\n",
            "Training Classifier...\n",
            "Fold start on items 3280 - 4100\n",
            "Training Classifier...\n",
            "Fold start on items 4100 - 4920\n",
            "Training Classifier...\n",
            "Fold start on items 4920 - 5740\n",
            "Training Classifier...\n",
            "Fold start on items 5740 - 6560\n",
            "Training Classifier...\n",
            "Fold start on items 6560 - 7380\n",
            "Training Classifier...\n",
            "Fold start on items 7380 - 8200\n",
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[60.2799471344467, 59.65151068538373, 60.2799471344467, 58.95256220964574]"
            ]
          },
          "metadata": {},
          "execution_count": 252
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "# a function to make the confusion matrix readable and pretty\n",
        "def confusion_matrix_heatmap(y_test, preds, labels):\n",
        "    \"\"\"Function to plot a confusion matrix\"\"\"\n",
        "    # pass labels to the confusion matrix function to ensure right order\n",
        "    cm = metrics.confusion_matrix(y_test, preds,labels=labels)\n",
        "    print(cm)\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm)\n",
        "    plt.title('Confusion matrix of the classifier')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticks(np.arange(len(labels)))\n",
        "    ax.set_yticks(np.arange(len(labels)))\n",
        "    ax.set_xticklabels( labels, rotation=45)\n",
        "    ax.set_yticklabels( labels)\n",
        "\n",
        "    for i in range(len(cm)):\n",
        "        for j in range(len(cm)):\n",
        "            text = ax.text(j, i, cm[i, j],\n",
        "                           ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    # fix for mpl bug that cuts off top/bottom of seaborn viz:\n",
        "    b, t = plt.ylim() # discover the values for bottom and top\n",
        "    b += 0.5 # Add 0.5 to the bottom\n",
        "    t -= 0.5 # Subtract 0.5 from the top\n",
        "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
        "    plt.show() # ta-da!\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "f69ImQbghi-e"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_heatmap(global_test[0],global_predict[0],[\"REAL\",\"FAKE\"]) #Plotting confusion matrix on the last fold of data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "b31LduEZUw8E",
        "outputId": "cd2ab432-8789-4c56-f987-c60bf97cbdb6"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[362 117]\n",
            " [192 141]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XB-N84Qb9zu"
      },
      "execution_count": 254,
      "outputs": []
    }
  ]
}