{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RjwBi-Z0HVg"
      },
      "source": [
        "# Text classification for Fake News Detection\n",
        "\n",
        "This coursework will involve you implementing functions for a text classifier, which you will train to detect **fake news** in a corpus of approx. 10,000 statements, which will be split into a 80%/20% training/test split. \n",
        "\n",
        "In this template you are given the basis for that implementation, though some of the functions are missing, which you have to fill in.\n",
        "\n",
        "Follow the instructions file **NLP_Assignment_1_Instructions.pdf** for details of each question - the outline of what needs to be achieved for each question is as below.\n",
        "\n",
        "You must submit all **ipython notebooks and extra resources you need to run the code if you've added them** in the code submission, and a **2 page report (pdf)** in the report submission on QMPlus where you report your methods and findings according to the instructions file for each question."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dAM69FEC0HVi",
        "outputId": "ccd9585f-a881-489e-a4f9-c5f9d2c2c03a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wJ9KlQqM0HVi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce4699b-2a18-4f22-d88d-06bd53374d15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import csv                               # csv reader\n",
        "from sklearn.svm import LinearSVC\n",
        "from nltk.classify import SklearnClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import precision_recall_fscore_support # to report on precision and recall\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "import sys #to print to file\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WtP1elvz0HVj"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    \"\"\"Load data from a tab-separated file and append it to raw_data.\"\"\"\n",
        "    with open(path) as f:\n",
        "        reader = csv.reader(f, delimiter='\\t')\n",
        "        for line in reader:\n",
        "            if line[0] == \"Id\":  # skip header\n",
        "                continue\n",
        "            (label, text) = parse_data_line(line)\n",
        "            raw_data.append((text, label))\n",
        "\n",
        "def split_and_preprocess_data(percentage):\n",
        "    \"\"\"Split the data between train_data and test_data according to the percentage\n",
        "    and performs the preprocessing.\"\"\"\n",
        "    num_samples = len(raw_data)\n",
        "    num_training_samples = int((percentage * num_samples))\n",
        "    for (text, label) in raw_data[:num_training_samples]:\n",
        "        train_data.append((to_feature_vector(pre_process(text)),label))\n",
        "    for (text, label) in raw_data[num_training_samples:]:\n",
        "        test_data.append((to_feature_vector(pre_process(text)),label))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Keo2Svjr0HVj"
      },
      "source": [
        "# Question 1: Input and Basic preprocessing (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h844YWeU0HVj"
      },
      "outputs": [],
      "source": [
        "def convert_label(label):\n",
        "    \"\"\"Converts the multiple classes into two,\n",
        "    making it a binary distinction between fake news and real.\"\"\"\n",
        "    # return label\n",
        "    # Converting the multiclass labels to binary label\n",
        "    labels_map = {\n",
        "        'true': 'REAL',\n",
        "        'mostly-true': 'REAL',\n",
        "        'half-true': 'REAL',\n",
        "        'false': 'FAKE',\n",
        "        'barely-true': 'FAKE',\n",
        "        'pants-fire': 'FAKE'\n",
        "    }\n",
        "    return labels_map[label]\n",
        "\n",
        "\n",
        "def parse_data_line(data_line):\n",
        "    \n",
        "    label=convert_label(data_line[1]) #label element: data_line[1] read from file\n",
        "    text=data_line[2] #statement element: data_line[2] read from file\n",
        "    return (label, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bFORDx3n0HVj"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Input: a string of one statement\n",
        "def pre_process(text):\n",
        "    # Sentence segmentation is already done as the sentences are provided as different rows\n",
        "    # word tokenisation\n",
        "    text = re.sub(r\"(\\w)([.,;:!?'\\\"”\\)])\", r\"\\1 \\2\", text) # separates punctuation at ends of strings by replacing the punctations by the string\n",
        "    text = re.sub(r\"([.,;:!?'\\\"“\\(\\)])(\\w)\", r\"\\1 \\2\", text) # separates punctuation at beginning of strings by replacing the punctations by the string\n",
        "    tokens = re.split(r\"\\s+\",text) # with space as delimeter it split the spaced text\n",
        "    # normalisation - only by lower casing for now\n",
        "    tokens = [t.lower() for t in tokens]\n",
        "    return tokens\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq0xN9c_0HVj"
      },
      "source": [
        "# Question 2: Basic Feature Extraction (20 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BbJqmEV10HVk"
      },
      "outputs": [],
      "source": [
        "global_feature_dict = {} # A global dictionary of features\n",
        "\n",
        "def to_feature_vector(tokens):\n",
        "    local_dict={}\n",
        "    for i in tokens:\n",
        "      if i in local_dict:\n",
        "        local_dict[i]+=1 # Adding 1 to the value of key if key already present\n",
        "      else:\n",
        "        local_dict[i]=1 # Adding key-value(value as 1) pair to the dictionary\n",
        "    for w in tokens:\n",
        "          try:\n",
        "            global_feature_dict[w] # Checks if the key is already present in the dictionary, do nothing\n",
        "          \n",
        "          except KeyError:   \n",
        "            i = len(global_feature_dict) + 1  # If it is not present then we add 1 to the length of the dictioanry\n",
        "                \n",
        "            global_feature_dict[w] = i # Then assign the new length as the value to the new key\n",
        "\n",
        "    # Hence the global dictionary has keys with their indexes\n",
        "    # and local dictionary is a Bag of Words model per sentence \n",
        "    return local_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "nVIgQ_O00HVk"
      },
      "outputs": [],
      "source": [
        "# TRAINING AND VALIDATING OUR CLASSIFIER\n",
        "\n",
        "def train_classifier(data):\n",
        "    print(\"Training Classifier...\")\n",
        "    pipeline =  Pipeline([('model', LinearSVC())])\n",
        "    return SklearnClassifier(pipeline).train(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8P5n9CS0HVk"
      },
      "source": [
        "# Question 3: Cross-validation (20 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5GXYdEee0HVk"
      },
      "outputs": [],
      "source": [
        "def cross_validate(dataset, folds):\n",
        "    fold_size = int(len(dataset)/folds) + 1\n",
        "    cv=np.array([])\n",
        "    accuracy=[]\n",
        "    precision=[]\n",
        "    recall=[]\n",
        "    f1=[]\n",
        "    j=0\n",
        "\n",
        "    for i in range(0,len(dataset),int(fold_size)):\n",
        "        train_fold=dataset[0:i]+dataset[i+fold_size:]  #training data for current fold\n",
        "        test_fold=dataset[i:i+fold_size]    #test data for current fold\n",
        "        print(\"Fold start on items %d - %d\" % (i, i+fold_size))\n",
        "        # FILL IN THE METHOD HERE\n",
        "\n",
        "        classifier=train_classifier(train_fold)# sending training data to LinearSVC\n",
        "        predict=predict_labels([x[0] for x in test_fold],classifier) #sending the classfier and the Bag of words of test fold\n",
        "        if i ==7380: # Value of item start of last fold\n",
        "          global_test.append([x[1] for x in test_fold]) #extracting label for the last test fold for Heatmap and confusion matrix in nect question\n",
        "          global_predict.append(predict) #extracting predicted output fot the last fold for Heatmap and confusion matrix in nect question\n",
        "          global_test_text.append([x[0] for x in test_fold]) # extracting the Bag of words of the last test to print to file in the next question\n",
        "        accuracy.append(accuracy_score([x[1] for x in test_fold],predict)) #calculating accuracy using label of test fold and predicted labels\n",
        "        precision.append(precision_score([x[1] for x in test_fold], predict, average='weighted')) #calculating precision using label of test fold and predicted labels\n",
        "        recall.append(recall_score([x[1] for x in test_fold], predict, average='weighted')) #calculating recall using label of test fold and predicted labels\n",
        "        f1.append(f1_score([x[1] for x in test_fold], predict, average='weighted')) #calculating f1 using label of test fold and predicted labels\n",
        "        \n",
        "    cv=[100*np.mean(accuracy),100*np.mean(precision),100*np.mean(recall),100*np.mean(f1)] #average*100 of all 10 folds for all 4 parameters\n",
        "        \n",
        "    return cv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "z3azSE_30HVk"
      },
      "outputs": [],
      "source": [
        "# PREDICTING LABELS GIVEN A CLASSIFIER\n",
        "\n",
        "def predict_labels(samples, classifier):\n",
        "    \"\"\"Assuming preprocessed samples, return their predicted labels from the classifier model.\"\"\"\n",
        "    return classifier.classify_many(samples)\n",
        "\n",
        "def predict_label_from_raw(sample, classifier):\n",
        "    \"\"\"Assuming raw text, return its predicted label from the classifier model.\"\"\"\n",
        "    return classifier.classify(to_feature_vector(preProcess(reviewSample)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xJsXhEG0HVk",
        "outputId": "5dc29eb4-3910-4110-bbec-7c7b898c84b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now 0 rawData, 0 trainData, 0 testData\n",
            "Preparing the dataset...\n",
            "Now 10241 rawData, 0 trainData, 0 testData\n",
            "Preparing training and test data...\n",
            "After split, 10241 rawData, 8192 trainData, 2049 testData\n",
            "Training Samples: \n",
            "8192\n",
            "Features: \n",
            "13560\n"
          ]
        }
      ],
      "source": [
        "# MAIN\n",
        "\n",
        "# loading reviews\n",
        "# initialize global lists that will be appended to by the methods below\n",
        "raw_data = []          # the filtered data from the dataset file\n",
        "train_data = []        # the pre-processed training data as a percentage of the total dataset\n",
        "test_data = []         # the pre-processed test data as a percentage of the total dataset\n",
        "global_test=[]         # to store label of last fold\n",
        "global_predict=[]      # to store prdiction for last fold\n",
        "global_test_text=[]    # to store bag of words for last fold\n",
        "\n",
        "# references to the data files\n",
        "data_file_path = 'fake_news.tsv'\n",
        "\n",
        "# Do the actual stuff (i.e. call the functions we've made)\n",
        "# We parse the dataset and put it in a raw data list\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing the dataset...\",sep='\\n')\n",
        "\n",
        "load_data(data_file_path) \n",
        "\n",
        "# We split the raw dataset into a set of training data and a set of test data (80/20)\n",
        "# You do the cross validation on the 80% (training data)\n",
        "# We print the number of training samples and the number of features before the split\n",
        "print(\"Now %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Preparing training and test data...\",sep='\\n')\n",
        "\n",
        "split_and_preprocess_data(0.8)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# We print the number of training samples and the number of features after the split\n",
        "print(\"After split, %d rawData, %d trainData, %d testData\" % (len(raw_data), len(train_data), len(test_data)),\n",
        "      \"Training Samples: \", len(train_data), \"Features: \", len(global_feature_dict), sep='\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo0XP9LL0HVl",
        "outputId": "40839ee3-706e-46b9-8785-1ab234ef5a57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold start on items 0 - 820\n",
            "Training Classifier...\n",
            "Fold start on items 820 - 1640\n",
            "Training Classifier...\n",
            "Fold start on items 1640 - 2460\n",
            "Training Classifier...\n",
            "Fold start on items 2460 - 3280\n",
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold start on items 3280 - 4100\n",
            "Training Classifier...\n",
            "Fold start on items 4100 - 4920\n",
            "Training Classifier...\n",
            "Fold start on items 4920 - 5740\n",
            "Training Classifier...\n",
            "Fold start on items 5740 - 6560\n",
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold start on items 6560 - 7380\n",
            "Training Classifier...\n",
            "Fold start on items 7380 - 8200\n",
            "Training Classifier...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[56.88922263606872, 56.97247193999616, 56.88922263606872, 56.88818090199837]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "cross_validate(train_data, 10)  # will work and output overall performance of p, r, f-score when cv implemented"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH3PcwAC0HVq"
      },
      "source": [
        "# 4. Error Analysis (10 marks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Oz3AZlu70HVq"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "# a function to make the confusion matrix readable and pretty\n",
        "def confusion_matrix_heatmap(y_test, preds, labels):\n",
        "    \"\"\"Function to plot a confusion matrix\"\"\"\n",
        "    # pass labels to the confusion matrix function to ensure right order\n",
        "    cm = metrics.confusion_matrix(y_test, preds,labels=labels) # sending last fold's label, predicted label and the Real & Fake strings\n",
        "    print(cm) # printing confusion matrix\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(cm)\n",
        "    plt.title('Confusion matrix of the classifier')\n",
        "    fig.colorbar(cax)\n",
        "    ax.set_xticks(np.arange(len(labels)))\n",
        "    ax.set_yticks(np.arange(len(labels)))\n",
        "    ax.set_xticklabels( labels, rotation=45)\n",
        "    ax.set_yticklabels( labels)\n",
        "\n",
        "    for i in range(len(cm)):\n",
        "        for j in range(len(cm)):\n",
        "            text = ax.text(j, i, cm[i, j],\n",
        "                           ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    \n",
        "    # fix for mpl bug that cuts off top/bottom of seaborn viz:\n",
        "    b, t = plt.ylim() # discover the values for bottom and top\n",
        "    b += 0.5 # Add 0.5 to the bottom\n",
        "    t -= 0.5 # Subtract 0.5 from the top\n",
        "    plt.ylim(b, t) # update the ylim(bottom, top) values\n",
        "    plt.show() # ta-da!\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_heatmap(global_test[0],global_predict[0],[\"REAL\",\"FAKE\"]) #Plotting confusion matrix on the last fold of data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "Z7mlAyMA8JFl",
        "outputId": "ae1c96d5-6f17-4a1b-939c-477fc94d197d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[307 172]\n",
            " [141 192]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAJnCAYAAAB78EF0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhlVXm//ftLdzNoMwiNiNDQqKABB4RWcUDBEVBBjQOoSIiIMWhEMYPEOeLPOGCcYkRxQFGCSggoghghQl4BARkERBsRmQS6mWfoft4/9i48NF1VPVSdqnP2/bmuffU+a0/rVJ2u5zxrrb12qgpJkjRcVpvqCkiSpIlngJckaQgZ4CVJGkIGeEmShpABXpKkIWSAlyRpCBngNWWSrJXk+CS3JPneKpznDUl+MpF1mypJdkxy6SScd4V/1klOTbLfRNdlqWv8VZLTJ/H8P06yT8/rjyZZmORPSTZLcnuSGZN1fWkqzZzqCmj6S/J64N3AE4DbgPOAQ6pqVf8wvxrYCNigqu5f2ZNU1ZHAkatYl0mXpIAtq2rBaPtU1WnA4yfh8mP+rJN8CHhcVb1xEq49Zapq15H1JJsBBwGbV9X1bfHsKamY1Adm8BpTkncD/wZ8jCZAbAb8O7DHBJx+c+C3qxLch0mSyfzC7c+6+ewu6gnuK22Sf1fSxKgqF5dlLsC6wO3Aa8bYZw2aLwDXtMu/AWu023YCrqLJmq4HrgX2bbd9GLgXuK+9xpuBDwHf7jn3PKCAme3rvwJ+T9OKcDnwhp7y03uOexbwS+CW9t9n9Ww7FfgX4P/a8/wEmDPKexup/z/01P8VwG7Ab4EbgYN79n868Avg5nbfLwCrt9t+3r6XO9r3+7qe8/8j8CfgWyNl7TGPba+xXfv60cANwE6j1Pcv2vd3M3ARsPtoP+uljttlqe3nL8/PCtgB+P/a650/Wr3afecCx7T1XwR8YZTf3WeBK4FbgXOAHZf6+Z7dbrsOOLQtXxP4dnvem9vf+UY972E/4IXAXcCS9j1+g4d+vtYFDm9/d1cDHwVm9NTz/4DPtNf56FT//3RxGW+Z8gq4TN+l/cN//8gfwFH2+QhwBvBIYMP2D/6/tNt2ao//CDCLJjDeCTyi3f4hHhzQl379wB9g4OHtH/bHt9s2BrZp1x8IEsD6wE3A3u1xe7WvN2i3nwpcBmwFrNW+/vgo722k/h9o6/+WNkB9B1gb2KYNGlu0+29PE/RmtnW/BDiw53xF0wy+9Pn/leaL0lr0BPh2n7cAFwMPA04CPjVKXWcBC4CDgdWB59ME5ccv62e7jOMfsn2snxWwCU2g242mJfBF7esNl3HuGTRfAD7T/h7XBJ6z9O+uff1GYIP2Z3gQzRefNdttvwD2btdnAzu0628Fjm9/RjPa38M6Pe9hv56fd+/Pdh4PDvD/BXy5reMjgbOAt/bU837gHW3d1prq/58uLuMtNtFrLBsAC2vsZt03AB+pquur6gaabHHvnu33tdvvq6oTaLKnle1jXgI8MclaVXVtVV20jH1eCvyuqr5VVfdX1XeB3wAv79nn61X126q6Czga2HaMa95HM97gPuAoYA7w2aq6rb3+xcBTAKrqnKo6o73uH2iCxfOW4z19sKruaevzIFX1FZrAfSbNl5p/HuU8O9AEvY9X1b1V9TPghzRfcFbFaD+rNwInVNUJVbWkqk6mya53W8Y5nk7T+vD3VXVHVd1do4zfqKpvV9Wi9mf4aZovPiOfl/uAxyWZU1W3V9UZPeUb0Hx5Wtz+Hm5dkTeZZKO27ge2dbye5gvJnj27XVNVn2/r9pDflTTdGOA1lkXAnHH6Gx8NXNHz+oq27IFzLPUF4U5WYmBTVd1B06z9N8C1SX6U5AnLUZ+ROm3S8/pPK1CfRVW1uF0f+aN+Xc/2u0aOT7JVkh+2I7RvpRm3MGeMcwPcUFV3j7PPV4AnAp+vqntG2efRwJVVtaSnbOn3vTJG+1ltDrwmyc0jC/Acmi8hS5sLXDHOF0UAkrwnySXtaP+baZrNR36Gb6ZpTfhNkl8meVlb/i2a1o2jklyT5BNJZq3g+9ycphXk2p7382WaTH7ElSt4TmlKGeA1ll8A99D0O4/mGpo/jiM2a8tWxh00zawjHtW7sapOqqoX0QSR39AEvvHqM1Knq1eyTiviSzT12rKq1qFpLs84x4z5OMcks2nGNRwOfCjJ+qPseg0wN0nv/+kVed8r+ljJK4FvVdV6PcvDq+rjo+y72XgD05LsSDPe4bU03Tjr0YyjCEBV/a6q9qIJuv8KfD/Jw9vWoQ9X1dY04y9eBrxpJd7PPTRjDEbezzpVtU3PPj56UwPFAK9RVdUtNP3PX0zyiiQPSzIrya5JPtHu9l3gfUk2TDKn3f/bK3nJ84Dntvcnrwu8d2RDko2S7JHk4TR/iG+nad5e2gnAVklen2RmktcBW9M0V0+2tWnGCdzeti68bant1wGPWcFzfhY4u6r2A34E/Mco+51Jk2H/Q/s72ommW+Ko5bzOdcC8pb4gjOXbwMuTvCTJjCRrJtkpyabL2PcsmoFrH0/y8HbfZy9jv7Vp+rlvAGYm+QCwzsjGJG9MsmHbSnFzW7wkyc5JntTez34rTZP9sj4bo6qqa2kGEX46yTpJVkvy2CTjdbFI05YBXmNq+0HfDbyP5g/vlcDbgWPbXT5K0/d6AXAhcG5btjLXOhn4z/Zc5/DgoLxaW49raEaWP4+HBlCqahFNBncQTRfDPwAvq6qFK1OnFfQe4PU0g9u+QvNeen0I+GbbBPza8U6WZA+agY4j7/PdwHZJ3rD0vlV1L01A3xVYSHMr45uq6jfLWfeRyW8WJTl3vJ2r6kqaWyUP5s+fi79nGX9T2i6OlwOPA/5Ic+fA65Zx2pOAE2nuULgCuJsHN4vvAlyU5HaaLz57tn3hjwK+TxPcLwH+l6bZfkW9iWaA4sU0AzO/z7K7HKSBkCpbnSRJGjZm8JIkDSEDvCRJQ8gArwmRZLzR4tJASjI/yQZTXQ9pRRngNVE2AFiBUdjStJfkJTQDJld1PgGp7/xjrFWSxiOBK5LsXlVLDPIaBkl2Af4f8K6quiDJI5KsPdX1kpaXf4i1SqpxPbAv8PUku40EeZ+zrUGV5Mk0mfu/VNWpSebSPIPgqVNbM2n5GeA1IarqaJqpRI9K8tJ2MpICSPLynmlFpWktyeY099//FtgwyVNo5jQ4oap+PqWVk1aAAV4rJckuST6Q5FkjZVV1LE0mf1SSl7WZ/FtpZl9b3glXpCmTZAvgqKq6Cdgf2J1mwpvjqurzPfvtmmTDKaqmtFzGnBtaGsNzaWZY2yXJr4EvAr+vqh+0I+q/keSHNE8S262qFkxhXaXltSZAktWr6rIk+9M8Y2BxkvWr6sYke9HM4LcHzSx+0rRkgNfKOh7Ykub52P9EM/Xo1kneXVXfT3IjTebz/Ko6fwrrKY0ryTbAZcD1wN1VdW+S1arqmiTvpJn6d3GSu2laqV5XVb+fwipL4zLAa7m1D1C5p6our6pfJFmD5vnZByZ5PU2gn53kaponoD2qnSNdmraSPAw4gCZ7/1fgliQzRh4TXFV/aLuajqB5kt1rq+riKauwtJyci17LJcluwPuBvUea25M8jqaf8lKaJsv9aB4G8yzg1Kq6fIqqKy23tktpa5rM/C9onvj3UZon2/2O5jnx99I8zObuqurHo4elVWaA17jayT4+BHyoqk5qn1FeNE/e+hLtU8xGRhgnSfnB0gBp527YmuaJffsAPwbuoAnuGwEPp3kq4VVTVklpBdlErzEleRLNH7sXVtXPkjwW+DLw7nbyj0OArYAHshqDu6a7JDsChwL/DFxRVZcmuZimif5GmoB+QHsnyCyAqrpvyiosrQRvk9My9cwt/wfgv4DXJpkHHAac1Ab31arqQuDnwE5ObKMBsilNc/yzgcOTvBHYoKoupRlQV8B3kqxZVfcZ3DWIDPAazeoAVXUb8AZgNs0o42Or6pNtcF+SZFtgEXDiyKAkabpKsnG7ehJwMc2o+fcCuwCHJnlnOzr+K8AlwCOmpKLSBLAPXg+R5MU097ifD1xQVcckeTjNhDUzqur17X5vpumvfG1V/WnKKiwthyQvBT4I7FFV1ybZFXhlVe3f3tv+aeBPwLU0t4F+s6rumroaS6vGDF4P0j5g41+AnwIBdk2yZVXdAfwtzb3AR7RNmvsCf2tw13TXfq7/CfhAG9xnAr8C5iQ5gOYOkX2qajvgKOC/DO4adGbwekCS9YGFNBnO8Uk2BQ4B/qOqftHuszrNvNwvBp7m/cCa7no+16+qqmPbgaLvr6q/SnIwzS1xb6iq705pRaUJ5ih6PaCdhvPlwCeS/G9VXZVkDvDJJGcDfwS+TvNQmTWq6tqprK+0PHo+1/+S5PfAZ4AT2s2fpbkN7jLwFk8NFwO8HqSqfpRkCXBOkhNpunE+DWxIM5HNNjTPx75xCqsprZD2c70YOA84uKo+3d77fjfNANL9gbMM7homNtFrmZK8EPgJsHFVXdeWrQasX1ULp7Ry0kpK8iLg88AzquqWtmwWsKkzL2rYGOA1qnaU8aeBnarq+qmujzQR2s/1vwHPtCVKw8wmeo2qqn7cDqo7Mcn8qloy1XWSVlXP5/qnfq41zMzgNa4ks6vq9qmuhzSR/Fxr2BngJUkaQk50I0nSEDLAS5I0hAzwkiQNIQO8VkmS/ae6DtJE83OtYWCA16ryD6GGkZ9rDTwDvCRJQ2hob5ObM2dOzZs3b6qrMfRuuOEGNtxww6muhjSh/Fz3xznnnLOwqvr2g37Jzg+vRTcu7su1zrngnpOqape+XGwUQzuT3bx58zj77LOnuhqSpFEkuaKf11t042LOOmmzvlxrxsa/m9OXC43BJnpJkobQ0GbwkiT1KmAJ3Xn0gBm8JElDyAxektQRxeIOPTzQDF6SpCFkBi9J6oSmD344bw1fFjN4SZKGkBm8JKkzHEUvSZIGmhm8JKkTimLxkE7Pvixm8JIkDSEzeElSZziKXpIkDTQDvCRJQ8gmeklSJxSw2CZ6SZI0yMzgJUmd4SA7SZI0aZKsmeSsJOcnuSjJh9vyLZKcmWRBkv9Msnpbvkb7ekG7fd541zDAS5I6oYDFVX1ZlsM9wPOr6inAtsAuSXYA/hX4TFU9DrgJeHO7/5uBm9ryz7T7jckAL0lSn1Xj9vblrHYp4PnA99vybwKvaNf3aF/Tbn9Bkox1DQO8JKkzlvRpWR5JZiQ5D7geOBm4DLi5qu5vd7kK2KRd3wS4EqDdfguwwVjnN8BLkjTx5iQ5u2fZf+kdqmpxVW0LbAo8HXjCRFbAUfSSpE4oqp/3wS+sqvnLs2NV3ZzkFOCZwHpJZrZZ+qbA1e1uVwNzgauSzATWBRaNdV4zeEmS+izJhknWa9fXAl4EXAKcAry63W0f4L/b9ePa17Tbf1Y19mg+M3hJUjcULJ4+t8FvDHwzyQyaZPvoqvphkouBo5J8FPgVcHi7/+HAt5IsAG4E9hzvAgZ4SZL6rKouAJ66jPLf0/THL11+N/CaFbmGAV6S1AnF8o9wHwb2wUuSNITM4CVJHREWM+bcMEPFDF6SpCFkgJckaQjZRC9J6oQClkyf2+QmnRm8JElDyAxektQZDrKTJEkDzQxektQJhRm8JEkacGbwkqTOWFJm8JIkaYCZwUuSOsE+eEmSNPDM4CVJnVCExR3Ka7vzTiVJ6hAzeElSZziKXpIkDTQzeElSJziKXpIkDTwDvCRJQ8gmeklSR4TF1Z28tjvvVJKkDjGDlyR1QgFLOpTXduedSpLUIWbwkqTO8DY5SZI00MzgJUmdUOUoekmSNODM4CVJnbHEPnhJkjTIzOAlSZ3QPGymO3ltd96pJEkdYgYvSeoIR9FLkqQBZwYvSeoE56KXJEkDzwAvSdIQsolektQZi8uJbiRJ0gAzg5ckdUIRJ7qRJEmDzQxektQZS5zoRpIkDTIzeElSJ/iwGUmSNPDM4CVJnVDE++AlSdJgM4OXJHWGD5uRJEkDzQxektQJVbDY++AlSdIgM4OXJHVEWIKj6CVJ0gAzwEuSNIRsopckdULhIDtJkjSJksxNckqSi5NclOSdbfm2Sc5Icl6Ss5M8vS1Pks8lWZDkgiTbjXcNM3hJUmdMo4fN3A8cVFXnJlkbOCfJycAngA9X1Y+T7Na+3gnYFdiyXZ4BfKn9d1TT5p1KktQVVXVtVZ3brt8GXAJsQtOTsE6727rANe36HsAR1TgDWC/JxmNdwwxektQJRVgyDR82k2Qe8FTgTOBA4KQkn6JJwp/V7rYJcGXPYVe1ZdeOdl4zeEmSJt6ctg99ZNl/WTslmQ38ADiwqm4F3ga8q6rmAu8CDl/ZCgxvBn/fr1nypy2nuhbShHnR6/ad6ipIE2rt2Y/evt/X7GMf/MKqmj/WDklm0QT3I6vqmLZ4H+Cd7fr3gK+261cDc3sO37QtG5UZvCRJfZYkNNn5JVV1aM+ma4DntevPB37Xrh8HvKkdTb8DcEtVjdo8D8OcwUuS1KOAJdPnPvhnA3sDFyY5ry07GHgL8NkkM4G7gZGm/ROA3YAFwJ3AuE16BnhJkvqsqk6HUSfGf0jXRVUVcMCKXMMAL0nqiLDYh81IkqRBZgYvSeqEadYHP+m6804lSeoQM3hJUmfYBy9JkgaaGbwkqROqYh+8JEkabAZ4SZKGkE30kqTOWGwTvSRJGmRm8JKkTihgibfJSZKkQWYGL0nqiNgHL0mSBpsZvCSpE5qHzdgHL0mSBpgZvCSpMxZ3KK/tzjuVJKlDzOAlSZ1QxD54SZI02MzgJUmdsaRDeW133qkkSR1iBi9J6oQqWGwfvCRJGmQGeEmShpBN9JKkzvA2OUmSNNDM4CVJndBMdNOdvLY771SSpA4xg5ckdcZi7IOXJEkDzAxektQJhaPoJUnSgDODlyR1hKPoJUnSgDODlyR1xhJH0UuSpEFmBi9J6gQfFytJkgaeGbwkqTMcRS9JkgaaAV6SpCFkE70kqROax8U6yE6SJA0wM3hJUmc40Y0kSRpoZvCSpE7wcbGSJGngmcFLkjrDiW4kSdJAM4OXJHVDeR+8JEkacGbwkqROKLwPXpIkDTgzeElSZ9gHL0mSJk2SuUlOSXJxkouSvLNn2zuS/KYt/0RP+XuTLEhyaZKXjHcNM3hJUidMs5ns7gcOqqpzk6wNnJPkZGAjYA/gKVV1T5JHAiTZGtgT2AZ4NPDTJFtV1eLRLmAGL0lSn1XVtVV1brt+G3AJsAnwNuDjVXVPu+369pA9gKOq6p6quhxYADx9rGsY4CVJmkJJ5gFPBc4EtgJ2THJmkv9N8rR2t02AK3sOu6otG5VN9JKkzuhjE/2cJGf3vD6sqg5beqcks4EfAAdW1a1JZgLrAzsATwOOTvKYlamAAV6SpIm3sKrmj7VDklk0wf3IqjqmLb4KOKaqCjgryRJgDnA1MLfn8E3bslHZRC9J6oSimaq2H8t4kgQ4HLikqg7t2XQssHO7z1bA6sBC4DhgzyRrJNkC2BI4a6xrmMFLktR/zwb2Bi5Mcl5bdjDwNeBrSX4N3Avs02bzFyU5GriYZgT+AWONoAcDvCSpQ6bLVLVVdTqMWpk3jnLMIcAhy3sNm+glSRpCZvCSpG6oaTXRzaQzg5ckaQiZwUuSOmGaTVU76czgJUkaQmbwkqTOMIOXJEkDzQxektQJIzPZdYUZvCRJQ8gMXpLUGWUGL0mSBpkBXpKkIWQTvSSpM6bLw2b6wQxekqQhZAYvSeqE8mEzkiRp0JnBS5I6w9vkJEnSQDOD1zhWJ+t/B7I6MBPuOZG6/XMwY1Oy7r/BauvBfb+mbvl74D6y9sGw+g7NoVkTVtuAun77qXwD0oO85x9fyg7PfBw333Qn++37FQDe98FXMHfuBgDMnr0Gt99+D2/d73C2nz+P/fbfmZmzZnD/fYv58pd+xnm/umIqq69V0q2paictwCdZDFzYXuNyYO+qujnJPOAS4NKe3Q+tqiPa47YFfgXsWlUn9pzv9qqaPVn11WjupW56E9SdwEyy/lEw6+fkYftSd34d7v4RWecjsNZr4K7vULd97M+HPmxvMnPrKau5tCwn/fgC/vuYs/nHg3d/oOyjHz72gfW/+dsXcMcd9wBwyy138b73fo9Fi25n3hYb8q+f3JPXvfrzfa+ztDIms4n+rqratqqeCNwIHNCz7bJ228hyRM+2vYDT2381HdSd7cpMyEygYI0d4O7m+1fddQxZ84UPOSxrvoy6+4f9q6e0HC684Epuve3uUbc/b+e/4Gc/vQiABb+7jkWLbgfgD5ffwOprzGTWrBl9qacmR1X6skwH/Wqi/wXw5PF2ShLgNcCLgNOSrFlVo/9PVJ+sRjY4FmZsBnceCff/EZbcBixuNi/+E6y20VKHPBpmbAr3/qLvtZVW1pOePJebbryDq6++6SHbnvu8J/C73/6J++5bPAU1k1bcpA+ySzIDeAFwXE/xY5Oc17Ps2JY/C7i8qi4DTgVeuoLX2j/J2UnOvmGR/wknzhJq0e7UDTvCrCfDzMeMf8haL2sz/CWTXjtpojz/hdtwyv9c9JDyzefN4S1v3ZnPfPrHU1ArTZSiuQ++H8t0MJkBfq0k5wF/AjYCTu7ZtnQT/Wlt+V7AUe36UaxgM31VHVZV86tq/oYb2Iw24eo26t4zYdZTYbW1gfZnPONRsOS6B+2aNV9q87wGymozwo47Pp5TTrnkQeVzNlybj3z0L/n4x47n2mtunqLaSStu0vvggc2B8OA++IdoM/2/BD6Q5A/A54Fdkqw9iXXUeLI+PPArWIOs8SxYfBnceyasuUuzy1qvou7+6Z+PmfEYWG0duO9X/a+vtJK2334L/vjHRSy84bYHyh4+ew0+9vHX8pUvn8pFv75qCmunCVHNbHb9WKaDSe+Dr6o7k/wdcGySfx9j1xcAF1TVS0YKknwTeCVwxKhHaXLN2JCs+wma74KrUXf/GO45hbp/AVn3MzD7XXD/xXDX9x84JGu9FO760ZRVWRrLP39gD56y7easu+5aHPW9t/PNr5/Gj084n52fvzU/W6p5/hWvnM+jN3kEe+/zHPbe5zkA/ON7vsvNN9+5rFNL00pqkr5qLH1bW5LjgaOB03jobXJfA54KnFlV/9FzzO7A26pq1yRLgGt6jjm0qg4d7frzn7JmnXXS3Il5M9I08KLX7TvVVZAm1C/P/SK33nZ13zqsH77lxvWEz/11X6517m4fO6eq5vflYqOYtAx+6XvWq+rlPS/XWs5zHEc7OK+qnHVPkqTlZNCUJGkIOVWtJKkTCh82I0mSBpwZvCSpI6bPJDT9YAYvSdIQMoOXJHXGdJmEph/M4CVJGkJm8JKkznAUvSRJGmhm8JKkTmgeBGMGL0mSBpgZvCSpM7wPXpIkDTQzeElSZ3gfvCRJGmhm8JKkznAUvSRJGmgGeEmShpBN9JKkTihiE70kSRpsZvCSpM7o0F1yZvCSJA0jM3hJUjf4sBlJkjTozOAlSd3RoU54M3hJkoaQGbwkqTPsg5ckSQPNDF6S1Bk+LlaSJE2aJHOTnJLk4iQXJXnnUtsPSlJJ5rSvk+RzSRYkuSDJduNdwwxektQJxbTqg78fOKiqzk2yNnBOkpOr6uIkc4EXA3/s2X9XYMt2eQbwpfbfUZnBS5LUZ1V1bVWd267fBlwCbNJu/gzwDzz4pr49gCOqcQawXpKNx7qGGbwkqRsKmD4Z/AOSzAOeCpyZZA/g6qo6P3lQXTcBrux5fVVbdu1o5zXAS5I08eYkObvn9WFVddjSOyWZDfwAOJCm2f5gmub5VWaAlyRp4i2sqvlj7ZBkFk1wP7KqjknyJGALYCR73xQ4N8nTgauBuT2Hb9qWjcoAL0nqjOlym1yaCH44cElVHQpQVRcCj+zZ5w/A/KpamOQ44O1JjqIZXHdLVY3aPA8GeEmSpsKzgb2BC5Oc15YdXFUnjLL/CcBuwALgTmDf8S5ggJckdcc0yeCr6nRgzBF/VTWvZ72AA1bkGt4mJ0nSEDKDlyR1RKbTRDeTzgxekqQhZAYvSeqOadIH3w9m8JIkDSEzeElSN9S0etjMpDODlyRpCJnBS5K6wz54SZI0yMzgJUkdYh+8JEkaYGbwkqTusA9ekiQNMgO8JElDyCZ6SVJ32EQvSZIGmRm8JKkbCnCqWkmSNMjM4CVJnVH2wUuSpEFmBi9J6g4zeEmSNMjM4CVJ3eEoekmSNMjM4CVJnRH74CVJ0iAzg5ckdUPhKHpJkjTYzOAlSR0RR9FLkqTBZoCXJGkI2UQvSeoOB9lJkqRBZgYvSeoOM3hJkjTIzOAlSd1hBi9JkgaZGbwkqRsKJ7rplcYbk3ygfb1ZkqdPftUkSdLKWp4m+n8Hngns1b6+DfjipNVIkqRJkurPMh0sTxP9M6pquyS/Aqiqm5KsPsn1kiRJq2B5Avx9SWbQjj1MsiGwZFJrJUnSZJgm2XU/LE8T/eeA/wIemeQQ4HTgY5NaK0mStErGzeCr6sgk5wAvAAK8oqoumfSaSZKklTZugE+yGXAncHxvWVX9cTIrJkmSVt7y9MH/iKbXIsCawBbApcA2k1gvSZIm3HQZ4d4Py9NE/6Te10m2A/520mo0QX57wcN4yaO3nepqSBPmln3WnOoqSBNq8UVOpjqZVngmu6o6N8kzJqMykiRNqg7NZLc8ffDv7nm5GrAdcM2k1UiSJK2y5cng1+5Zv5+mT/4Hk1MdSZI0EcYM8O0EN2tX1Xv6VB9JkiZH4UQ3AElmVtVi4Nl9rI8kSZoAY2XwZ9H0t5+X5Djge8AdIxur6phJrpskSROrQxn88vTBrwksAp7Pn++HL8AAL0nSNDVWgH9kO4L+1/w5sI/o0HcgSdKwcKKbxgxgNg8O7CM69COSJGnwjBXgr62qj/StJpIkTbZpkp4mmQscAWxEU6vDquqzST4JvBy4F7gM2Leqbm6PeS/wZmAx8HdVddJY1xhrnsDuTPcjSVJ/3Q8cVFVbAzsAByTZGjgZeGJVPRn4LfBegHbbnjTPgdkF+Pf2VvZRjRXgX7Dq9ZckaRqpPi3jVaPq2qo6t12/DbgE2KSqflJV97e7nQFs2qqJtB4AABGuSURBVK7vARxVVfdU1eXAAuDpY11j1ABfVTeOX0VJkrQqkswDngqcudSmvwZ+3K5vAlzZs+2qtmxUK/ywGUmSBlGqr6Po5yQ5u+f1YVV12EPqlMymmf79wKq6taf8n2ma8Y9c2QoY4CVJmngLq2r+WDskmUUT3I/snTwuyV8BLwNeUFUjX0muBub2HL5pWzYqH8YrSeqOSn+WcSQJcDhwSVUd2lO+C/APwO5VdWfPIccBeyZZI8kWwJY0M86OygxekqT+ezawN3BhkvPasoOBzwFrACc33wE4o6r+pqouSnI0cDFN0/0B7fNiRmWAlyR1xzS5D76qTmfZt6OfMMYxhwCHLO81bKKXJGkIGeAlSRpCNtFLkjqjSw+bMYOXJGkImcFLkrrDDF6SJA0yM3hJUjf0d6raKWcGL0nSEDKDlyR1hxm8JEkaZGbwkqTuMIOXJEmDzAxektQZjqKXJEkDzQAvSdIQMsBLkjSE7IOXJHWHffCSJGmQGeAlSRpCNtFLkrrBh81IkqRBZwYvSeoOM3hJkjTIzOAlSd1hBi9JkgaZGbwkqROCo+glSdKAM4OXJHWHGbwkSRpkZvCSpG5wJjtJkjTozOAlSd1hBi9JkgaZGbwkqTvM4CVJ0iAzwEuSNIRsopckdYa3yUmSpIFmBi9J6g4zeEmSNMjM4CVJ3VCYwUuSpMFmBi9J6gxH0UuSpIFmBi9J6g4zeEmSNMjM4CVJnWEfvCRJGmhm8JKk7jCDlyRJg8wMXpLUDc5kJ0mSBp0BXpKkIWQTvSSpE9IuXWEGL0nSEDKDlyR1h4PsJEnSIDPAS5I6I9WfZdx6JHOTnJLk4iQXJXlnW75+kpOT/K799xFteZJ8LsmCJBck2W68axjgJUnqv/uBg6pqa2AH4IAkWwP/BPxPVW0J/E/7GmBXYMt22R/40ngXMMBLkrqj+rSMV42qa6vq3Hb9NuASYBNgD+Cb7W7fBF7Rru8BHFGNM4D1kmw81jUM8JIkTaEk84CnAmcCG1XVte2mPwEbteubAFf2HHZVWzYqR9FLkrqjf6Po5yQ5u+f1YVV12NI7JZkN/AA4sKpuTf58p35VVbLyD7g1wEuSNPEWVtX8sXZIMosmuB9ZVce0xdcl2biqrm2b4K9vy68G5vYcvmlbNiqb6CVJ3dCnEfTLOYo+wOHAJVV1aM+m44B92vV9gP/uKX9TO5p+B+CWnqb8ZTKDlySp/54N7A1cmOS8tuxg4OPA0UneDFwBvLbddgKwG7AAuBPYd7wLGOAlSd0xTWayq6rTGX1q/BcsY/8CDliRa9hEL0nSEDKDlyR1xsqPSR88BniN6aDD38YzXro9N19/C/s/+aAHbXv1u1/GWz+1D3+54V9z66LbmPv4R/Oerx3A47bbgq+/77t8/9PHT1GtpdF94K9fzHOe8hhuuvVOXvf+IwDYcu4c3vumF/KwNVfnmoW38P4v/5g77r6XZ2y9GW9/zY7MmjmD++5fzGeP/jlnX3LlOFeQpodJbaJPsjjJeT3LvLb8wCR3J1m3Z9+dkvyw5/VHk5yYZI0kpya5tOc835/MeuvPfvKNUzl410MeUr7hphuw/YuewnVX3PBA2W033s4X3/k1A7umteNPv4h3HHrMg8ret++L+cL3T2fP9x/BqecuYO9dm7ubbr79Lt712WPZ8/1H8KGvnshH3rLrVFRZWimT3Qd/V1Vt27P8oS3fC/gl8KplHZTkfTQjDF9ZVfe0xW/oOc+rJ7neal142iXcduPtDyn/m0P/iq/847dpxn00br7hVn579mXcf9/9/ayitEJ+9durufX2ux9UtvlGj+DcS68C4MyLruD5228JwKV/vIGFN98BwGVXL2KNWTOZNXNGfyusiTVNpqrth74PskvyWGA28D6aQL/09oNoJtV/eVXd1efqaTk8c/f5LLrmRn5/wRVTXRVpQlx2zSKe99THAvDC+Vux0fprP2SfF8zfkt9ccR333b+439WTVspk98Gv1XN/3+VV9UpgT+Ao4DTg8Uk2qqrr2n2eDTwe2L6qlk4bj0wyEvBPrqq/n+S6axnWWGt19nrvq/inl3x0qqsiTZiPHH4Sf/+Gndlv9x34+XmXcd/iBwfxxzx6A97xmh054FM/mKIaaqI4yG7i3FVV2y5VthdN0/uSJD8AXgN8od22AHgE8CKa6ft6vaGqzmYMSfaneYwea/KwVa27lmHjxz6KR23xSL583ieBpi/+S+d8grc/473cdN3NU1w7aeVc8aebePunm375zTZaj+c8+TEPbHvkI2bzyXfszge/ciJX33DLVFVRWmF9HUWf5Ek0z7I9uZ1Qf3Xgcv4c4K8D3gD8T5Ibq+qUFTl/O5H/YQDrZP0OfU/rnz/8+o+89lH7PfD6W7//Igc87Z+4ddFtU1gradU8Yu21uOm2u0jgzS/fgR+cej4As9dag3878JV84funcf6Ca6a4llpl06h/vB/6fZvcXsCHqur/jRQkuTzJ5iOvq+q3SV4FHJvkpVV13rJOpP44+Mh38uSdtmHdOWvznT/+B0d86GhO/NrPlrnvIzZajy/+8uM8bJ21qCXFq975Uvbb5l3ceZtDKTR9HPLW3dj+CZuy3uy1+NGn38Jhx/6CtdacxWue3zQ2nnLO7zjutIsAeN0Lt2XuRuux3+47sN/uOwDw9k/9gJv8TGsApHcU9ISfPLm9qmb3vP49sFtV/aan7FCazP1M4D1V9bK2/MXAV4GdaSbk3xgY+V+1sKpeONa118n69Yw8ZLY/aWDdtM8zp7oK0oS65PjPcMfCK0ebrnXCPWzDufWEV727L9f61WHvPme8p8lNtknN4HuDe/v6McvYp/enfWpP+U+AzdqXO01C9SRJGlrOZCdJ6oTQrVH0PmxGkqQhZAYvSeoOM3hJkjTIzOAlSZ2RSbxzbLoxg5ckaQiZwUuSuqFjM9mZwUuSNIQM8JIkDSGb6CVJneFEN5IkaaCZwUuSusMMXpIkDTIzeElSZ9gHL0mSBpoZvCSpO8zgJUnSIDODlyR1Q9kHL0mSBpwZvCSpO8zgJUnSIDODlyR1QrAPXpIkDTgzeElSd1R3UngzeEmShpABXpKkIWQTvSSpMxxkJ0mSBpoZvCSpGwonupEkSYPNDF6S1BlZMtU16B8zeEmShpAZvCSpO+yDlyRJg8wMXpLUGd4HL0mSBpoZvCSpGwofNiNJkgabGbwkqTPsg5ckSQPNDF6S1B1m8JIkaZAZ4CVJGkI20UuSOiE4yE6SJE2iJF9Lcn2SX/eUbZvkjCTnJTk7ydPb8iT5XJIFSS5Ist3yXMMAL0nqhqr+LeP7BrDLUmWfAD5cVdsCH2hfA+wKbNku+wNfWp4LGOAlSeqzqvo5cOPSxcA67fq6wDXt+h7AEdU4A1gvycbjXcM+eElSZ0zzPvgDgZOSfIomAX9WW74JcGXPfle1ZdeOdTIzeEmSJt6cth99ZNl/OY55G/CuqpoLvAs4fFUqYAYvSeqO/mXwC6tq/goesw/wznb9e8BX2/Wrgbk9+23alo3JDF6SpOnhGuB57frzgd+168cBb2pH0+8A3FJVYzbPgxm8JKlDpksffJLvAjvRNOVfBXwQeAvw2SQzgbtpRswDnADsBiwA7gT2XZ5rGOAlSeqzqtprlE3bL2PfAg5Y0WsY4CVJ3VDAkmmSwveBffCSJA0hM3hJUnd0J4E3g5ckaRiZwUuSOmO6jKLvBzN4SZKGkAFekqQhZBO9JKk7lu9RrkPBDF6SpCFkBi9J6gwH2UmSpIFmBi9J6obCiW4kSdJgM4OXJHVCgDiKXpIkDTIzeElSdyyZ6gr0jxm8JElDyAxektQZ9sFLkqSBZgYvSeoG74OXJEmDzgxektQR5dPkJEnSYDODlyR1hk+TkyRJA80AL0nSELKJXpLUHQ6ykyRJg8wMXpLUDQXxYTOSJGmQmcFLkrrDPnhJkjTIhjaD32r7x3Dy2d+b6mpIkkaRHHRO3y/anQTeDF6SpGE0tBm8JElLi33wkiRpkJnBS5K6wwxekiQNMjN4SVI3FOBMdpIkaZCZwUuSOiGUo+glSdJgM8BLkjSEbKKXJHWHTfSSJGmQmcFLkrrDDF6SJA0yM3hJUjc40Y0kSRp0ZvCSpM5wohtJkjTQzOAlSd1hBi9JkgaZGbwkqSPKDF6SJA02M3hJUjcUZvCSJGmwGeAlSd2xpE/LOJJ8Lcn1SX69VPk7kvwmyUVJPtFT/t4kC5JcmuQly/NWbaKXJKn/vgF8AThipCDJzsAewFOq6p4kj2zLtwb2BLYBHg38NMlWVbV4rAuYwUuS1GdV9XPgxqWK3wZ8vKruafe5vi3fAziqqu6pqsuBBcDTx7uGAV6S1Bmp6suykrYCdkxyZpL/TfK0tnwT4Mqe/a5qy8ZkE70kSRNvTpKze14fVlWHjXPMTGB9YAfgacDRSR6zshUwwEuSuqN/t8ktrKr5K3jMVcAxVVXAWUmWAHOAq4G5Pftt2paNySZ6SZKmh2OBnQGSbAWsDiwEjgP2TLJGki2ALYGzxjuZGbwkqRsKWDI9JrpJ8l1gJ5qm/KuADwJfA77W3jp3L7BPm81flORo4GLgfuCA8UbQgwFekqS+q6q9Rtn0xlH2PwQ4ZEWuYYCXJHWED5uRJEkDzgxektQdZvCSJGmQmcFLkrrDDF6SJA0yM3hJUjdMo/vg+8EMXpKkIWQGL0nqiIJaMtWV6BszeEmShpABXpKkIWQTvSSpO7xNTpIkDTIzeElSN3ibnCRJGnRm8JKk7rAPXpIkDTIzeElSd5jBS5KkQWYGL0nqiDKDlyRJg80MXpLUDQUs8WEzkiRpgJnBS5K6wz54SZI0yMzgJUndYQYvSZIGmQFekqQhZBO9JKkjysfFSpKkwWYGL0nqhoIqJ7qRJEkDzAxektQd9sFLkqRBZgYvSeoOJ7qRJEmDzAxektQNVT4uVpIkDTYzeElSd9gHL0mSBpkZvCSpM8o+eEmSNMjM4CVJHVH2wUuSpMFmgJckaQjZRC9J6obCh81IkqTBZgYvSeqO8jY5SZI0wMzgJUmdUEDZBy9JkgaZGbwkqRuq7IOXJEmDzQxektQZ9sFLkqSBZgYvSeoO++AlSdIgSw3po/OS3ABcMdX16IA5wMKproQ0wfxc98fmVbVhvy6W5ESa320/LKyqXfp0rWUa2gCv/khydlXNn+p6SBPJz7WGgU30kiQNIQO8JElDyACvVXXYVFdgOkmyOMl5SX6d5HtJHrYK5/pGkle3619NsvUY++6U5FkrcY0/JOlXn+Qg8XOtgWeA1yqpKv8QPthdVbVtVT0RuBf4m96NSVbq1tSq2q+qLh5jl52AFQ7wWjY/1xoGBnhp8pwGPK7Nrk9LchxwcZIZST6Z5JdJLkjyVoA0vpDk0iQ/BR45cqIkpyaZ367vkuTcJOcn+Z8k82i+SLyrbT3YMcmGSX7QXuOXSZ7dHrtBkp8kuSjJV4H090ciqV+c6EaaBG2mvitwYlu0HfDEqro8yf7ALVX1tCRrAP+X5CfAU4HHA1sDGwEXA19b6rwbAl8Bntuea/2qujHJfwC3V9Wn2v2+A3ymqk5PshlwEvAXwAeB06vqI0leCrx5Un8QkqaMAV6aWGslOa9dPw04nKbp/KyqurwtfzHw5JH+dWBdYEvgucB3q2oxcE2Sny3j/DsAPx85V1XdOEo9XghsnTyQoK+TZHZ7jVe1x/4oyU0r+T4lTXMGeGli3VVV2/YWtEH2jt4i4B1VddJS++02gfVYDdihqu5eRl0kdYB98FL/nQS8LcksgCRbJXk48HPgdW0f/cbAzss49gzguUm2aI9dvy2/DVi7Z7+fAO8YeZFk5EvHz4HXt2W7Ao+YsHclaVoxwEv991Wa/vVzk/wa+DJNa9p/Ab9rtx0B/GLpA6vqBmB/4Jgk5wP/2W46HnjlyCA74O+A+e0gvov582j+D9N8QbiIpqn+j5P0HiVNMaeqlSRpCJnBS5I0hAzwkiQNIQO8JElDyAAvSdIQMsBLkjSEDPCSJA0hA7wkSUPIAC9J0hD6/wEZM1HmEHRwCAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(global_predict[0])):\n",
        "      if global_predict[0][i]==\"REAL\" and global_test[0][i]==\"FAKE\": # Predicted Real but is Fake, False Positive\n",
        "        original_stdout = sys.stdout\n",
        "        with open('False_Positive.rtf', 'a+') as f:\n",
        "            f.seek(0) # Move read cursor to the start of file.\n",
        "            data=f.read(100)  # If file is not empty then append '\\n'\n",
        "            if len(data) > 0 :\n",
        "              f.write(\"\\n\")\n",
        "            f.write(str(global_test_text[0][i])) # Append text at the end of file"
      ],
      "metadata": {
        "id": "r48wFFOPRTRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,len(global_predict[0])):\n",
        "      if global_predict[0][i]==\"FAKE\" and global_test[0][i]==\"REAL\": # Predicted Fake but is Real, False Negative\n",
        "        original_stdout = sys.stdout\n",
        "        with open('False_Negative.rtf', 'a+') as f:\n",
        "            f.seek(0) # Move read cursor to the start of file.\n",
        "            data=f.read(100)  # If file is not empty then append '\\n'\n",
        "            if len(data) > 0 :\n",
        "              f.write(\"\\n\")\n",
        "            f.write(str(global_test_text[0][i])) # Append text at the end of file"
      ],
      "metadata": {
        "id": "dAaOTH0cRB9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pl5IA2tc0HVq"
      },
      "source": [
        "# Questions 5 (20%) and 6 (20%) (recommend starting a new notebook)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wkktwpn00HVr"
      },
      "outputs": [],
      "source": [
        "# Finally, check the accuracy of your classifier by training on all the traning data\n",
        "# and testing on the test set\n",
        "# Will only work once all functions are complete\n",
        "functions_complete = False  # set to True once you're happy with your methods for cross val\n",
        "if functions_complete:\n",
        "    print(test_data[0])   # have a look at the first test data instance\n",
        "    classifier = train_classifier(train_data)  # train the classifier\n",
        "    test_true = [t[1] for t in test_data]   # get the ground-truth labels from the data\n",
        "    test_pred = predict_labels([x[0] for x in test_data], classifier)  # classify the test data to get predicted labels\n",
        "    final_scores = precision_recall_fscore_support(test_true, test_pred, average='weighted') # evaluate\n",
        "    print(\"Done training!\")\n",
        "    print(\"Precision: %f\\nRecall: %f\\nF Score:%f\" % final_scores[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTwY_6ft0HVr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
